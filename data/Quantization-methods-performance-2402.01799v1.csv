Method,Inference Engine,WM (GB),RM (GB),Tokens/s,Perplexity
Baseline FP16,PyTorch,12.55,26.16,30.90,5.85
GPTQ 2bit,PyTorch,2.11,2.98,20.91,NaN
GPTQ 3bit,PyTorch,2.87,3.86,21.24,7.36
GPTQ 4bit,PyTorch,3.63,4.65,21.63,6.08
GPTQ 8bit,PyTorch,6.67,7.62,21.36,5.86
AWQ 4bit GEMM,PyTorch,3.68,4.64,28.51,6.02
AWQ 4bit GEMV,PyTorch,3.68,4.64,31.81,6.02
QLoRA (NF4),PyTorch,3.56,4.84,19.70,6.02
LLM.int8(),PyTorch,6.58,7.71,5.24,5.89
K-Quants 4bit,Llama.cpp,3.80,7.38,104.45,5.96
OmniQuant 3bit,MLC-LLM,3.20,5.10,83.4,6.65
OmniQuant 4bit,MLC-LLM,3.80,5.70,134.2,5.97
