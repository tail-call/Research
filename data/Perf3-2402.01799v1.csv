Method,Hardware Support,Quantization Type,WM (GB),RM (GB),Tokens/sec,Perplexity
Llama.cpp,NVIDIA GPU,GGUF K-Quant 2bit,2.36,3.69,102.15,6.96
AMD GPU,GGUF 4bit (check),3.56,4.88,128.97,5.96
Apple Silicon,GGUF AWQ 4bit,3.56,4.88,129.25,5.91
CPU,GGUF K-Quant 4bit,3.59,4.90,109.72,5.87
GGUF 8bit,6.67,7.78,93.39,5.79
GGUF FP16,12.55,13.22,66.81,5.79
ExLlama,NVIDIA GPU,GPTQ 4bit,3.63,5.35,77.10,6.08
AMD GPU,,,,,
ExLlamav2,NVIDIA GPU,EXL2 2bit,2.01,5.21,153.75,20.21
AMD GPU,EXL2 4bit,3.36,6.61,131.68,6.12
GPTQ 4bit,3.63,6.93,151.30,6.03
EXL2 8bit,6.37,9.47,115.81,5.76
FP16,12.55,15.09,67.70,5.73
vLLM,NVIDIA GPU,AWQ GEMM 4bit,3.62,34.55,114.43,6.02
AMD GPU,GPTQ 4bit,3.63,36.51,172.88,6.08
FP16,12.55,35.92,79.74,5.85
TensorRT-LLM,NVIDIA GPU,AWQ GEMM 4bit,3.42,5.69,194.86,6.02
GPTQ 4bit,3.60,5.88,202.16,6.08
INT8,6.53,8.55,143.57,5.89
FP16,12.55,14.61,83.43,5.85
TGI,AMD GPU,AWQ GEMM 4bit,3.62,7.97,30.80,6.02
NVIDIA GPU,AWQ GEMV 4bit,3.62,7.96,34.22,6.02
Intel GPU,GPTQ 4bit,3.69,39.39,34.86,6.08
AWS Inferentia2,FP4,12.55,17.02,34.38,6.15
NF4,12.55,17.02,33.93,6.02
INT8,12.55,11.66,5.39,5.89
FP16,12.55,17.02,34.23,5.85
MLC-LLM,NVIDIA GPU,OmniQuant 3bit,3.2,5.1,83.4,6.65
AMD GPU,,OmniQuant 4bit,3.8,5.7,134.2,5.97
CPU, WebGPU,,AWQ GEMM 4bit,3.62,6.50,23.62,6.02
Apple Silicon,,Q4F16,3.53,6.50,189.07,-
Intel GPU,,Q3F16,2.84,5.98,185.47,-
WASM, Adreno Mali,FP16,12.55,15.38,87.37,5.85
